"""vLLM: A high-throughput and memory-efficient inference engine for LLMs"""

__version__ = "0.6.1"
