"""vLLM: A high-throughput and memory-efficient inference engine for LLMs"""

__version__ = "0.0.1.dev0"
